# gdab

Este é um projeto de exemplo para demonstrar a criação de uma pipeline de dados em tempo real usando Google Cloud Platform (GCP) e Apache Beam.

## Descrição

O projeto consiste em processar mensagens de um sistema de IoT em tempo real, transformá-las e armazená-las no BigQuery para análise. Utiliza várias ferramentas do GCP, como Pub/Sub, Dataflow e BigQuery.

## Ferramentas Utilizadas

- Google Cloud Platform (GCP)
- Google Pub/Sub
- Apache Beam
- Google Dataflow
- Google BigQuery
- Google Cloud Storage

## Estrutura do Projeto

- `pipeline.py`: Script principal da pipeline de dados.
- `publish_messages.py`: Script para publicar mensagens fictícias no Pub/Sub.
- `README.md`: Este arquivo de documentação.

## Como Executar

1. Configure seu ambiente GCP.
2. Instale as dependências necessárias.
3. Execute a pipeline.
4. Publique mensagens fictícias no Pub/Sub.
5. Analise os dados no BigQuery.

## Contato

Para mais informações, entre em contato: freitashbruno@gmail.com
